ğŸ§© Wafer Defect Multi-Task Classification (VLSI)

This repository presents a multi-task deep learning solution for wafer defect analysis in VLSI manufacturing.

The trained model is provided in ONNX format for efficient and framework-independent inference.

Due to GitHub file size limitations, the dataset is hosted externally, while the ONNX model is included directly in this repository.

ğŸ“ Repository Structure
Wafer-Defect-MultiTask/
â”œâ”€â”€ README.md
â””â”€â”€ wafer_defect_multitask_model.onnx

ğŸ“Š Dataset

Due to GitHub file size limitations, the dataset is hosted externally.

Dataset ZIP (Google Drive):
ğŸ‘‰ https://drive.google.com/file/d/1RySfy0fkOwzzTEh1w4gowlEppPftanUG/view?usp=drive_link

Dataset Structure

After downloading and extracting dataset.zip, the directory structure will be:

dataset/
â”œâ”€â”€ clean/
â”‚   â”œâ”€â”€ clean_si/
â”‚   â””â”€â”€ clean_ge/
â””â”€â”€ defected/
    â”œâ”€â”€ bridge_si/
    â”œâ”€â”€ bridge_ge/
    â”œâ”€â”€ cmp_si/
    â”œâ”€â”€ cmp_ge/
    â”œâ”€â”€ cracks_si/
    â”œâ”€â”€ cracks_ge/
    â”œâ”€â”€ ler_si/
    â”œâ”€â”€ ler_ge/
    â”œâ”€â”€ linebreak_si/
    â”œâ”€â”€ linebreak_ge/
    â”œâ”€â”€ pinhole_si/
    â”œâ”€â”€ pinhole_ge/
    â”œâ”€â”€ vias_si/
    â””â”€â”€ vias_ge/

ğŸ§  Model (ONNX)

Model Format: ONNX

Input Shape: 224 Ã— 224 Ã— 3 (RGB image)

Model Type: Multi-task Convolutional Neural Network

Model Outputs

The ONNX model produces three outputs:

Clean vs Defected classification (2 classes)

Material classification â€“ Silicon / Germanium (2 classes)

Defect type classification (7 classes)

ONNX Model File
wafer_defect_multitask_model.onnx

â–¶ï¸ ONNX Inference (Optional)

Example showing how to run inference using ONNX Runtime:

import onnxruntime as ort
import numpy as np

# Load ONNX model
session = ort.InferenceSession("wafer_defect_multitask_model.onnx")

# Get model input name
input_name = session.get_inputs()[0].name

# Dummy input (replace with actual preprocessed wafer image)
dummy_input = np.random.rand(1, 224, 224, 3).astype(np.float32)

# Run inference
outputs = session.run(None, {input_name: dummy_input})

print("Model outputs:", outputs)


This demonstrates how the ONNX model can be used for fast inference, edge deployment, and hardware-aware VLSI applications.
